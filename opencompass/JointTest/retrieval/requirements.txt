# nest_asyncio
torch==2.0.0
# transformers
# llama_index
# llama_index.llms.huggingface
# llama_index.embeddings.huggingface
# llama_index.vector_stores.milvus
# llama_index.finetuning
# bitsandbytes
# accelerate
# rake_nltk
# langchain
# langchain_openai
# nest_asyncio
# llama-index==0.10.18
# llama-index-agent-openai==0.1.5
# llama-index-cli==0.1.8
# llama-index-core==0.10.18.post1
# llama-index-embeddings-adapter==0.1.3
# llama-index-embeddings-huggingface==0.1.4
# llama-index-embeddings-openai==0.1.6
# llama-index-finetuning==0.1.4
# llama-index-indices-managed-llama-cloud==0.1.3
# llama-index-legacy==0.9.48
# llama-index-llms-gradient==0.1.2
# llama-index-llms-huggingface==0.1.3
# llama-index-llms-openai==0.1.7
# llama-index-multi-modal-llms-openai==0.1.4
# llama-index-postprocessor-cohere-rerank==0.1.2
# llama-index-program-openai==0.1.4
# llama-index-question-gen-openai==0.1.3
# llama-index-readers-file==0.1.9
# llama-index-readers-llama-parse==0.1.3
# llama-index-vector-stores-chroma==0.1.6
# llama-index-vector-stores-deeplake==0.1.2
# llama-parse==0.3.8
# llamaindex-py-client==0.1.13
# torch==2.1.2
# transformers==4.38.1
# bitsandbytes==0.42.0
# rake_nltk
# accelerate==0.27.2
# huggingface-hub==0.20.3
# pydantic==1.10.14
# llama_index.vector_stores.milvus
# llama_index.vector_stores.faiss
# requests==2.32.2