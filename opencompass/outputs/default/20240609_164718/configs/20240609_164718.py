ARC_c_datasets=[
    dict(abbr='ARC-c',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {question}\nA. {textA}\nB. {textB}\nC. {textC}\nD. {textD}\nAnswer:',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'question',
                'textA',
                'textB',
                'textC',
                'textD',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.arccDataset'),
    ]
datasets=[
    dict(abbr='mmlu_college_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college biology. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_biology',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    dict(abbr='mmlu_college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college chemistry. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_chemistry',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    dict(abbr='mmlu_college_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college computer science. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_computer_science',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    ]
fever_datasets=[
    dict(abbr='fever',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.feverEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Determine whether the given background supports, refutes, or provides not enough information about the claim, and respond with 'SUPPORT', 'REFUTE', or 'NOT ENOUGH INFO'. Do not generate any other content.\nClaim: {claim}\nAnswer: ",
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'claim',
                ],
            output_column='label'),
        type='opencompass.datasets.feverDataset'),
    ]
hotpotqa_datasets=[
    dict(abbr='HotpotQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.HotpotQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns='question',
            output_column='answer'),
        type='opencompass.datasets.HotpotQADataset'),
    ]
mmlu_datasets=[
    dict(abbr='mmlu_college_biology',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college biology. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_biology',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    dict(abbr='mmlu_college_chemistry',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college chemistry. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_chemistry',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    dict(abbr='mmlu_college_computer_science',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess')),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question about college computer science. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        name='college_computer_science',
        reader_cfg=dict(
            input_columns=[
                'input',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='target'),
        type='opencompass.datasets.mmluDataset'),
    ]
models=[
    dict(abbr='llama-3-8b-ragga-disturb',
        batch_padding=True,
        batch_size=6,
        generation_kwargs=dict(
            do_sample=False,
            eos_token_id=[
                128001,
                128009,
                ]),
        max_out_len=50,
        meta_template=dict(
            begin='<|start_header_id|>system<|end_header_id|>\n\n<|eot_id|>',
            round=[
                dict(begin='<|start_header_id|>user<|end_header_id|>\n\n',
                    end='<|eot_id|>',
                    role='HUMAN'),
                dict(begin='<|start_header_id|>assistant<|end_header_id|>\n\n',
                    generate=True,
                    role='BOT'),
                ]),
        model_kwargs=dict(
            device_map='auto',
            torch_dtype='torch.bfloat16'),
        path='/data/wxh/RAG/code/llama3-8b-instruct-ragga-disturb',
        run_cfg=dict(
            num_gpus=3),
        tokenizer_kwargs=dict(
            padding_side='left',
            truncation_side='left',
            trust_remote_code=True),
        tokenizer_path='/data/wxh/RAG/code/llama3-8b-instruct-ragga-disturb',
        type='opencompass.models.myModel'),
    ]
musique_datasets=[
    dict(abbr='MuSiQue',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.musiqueEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns='question',
            output_column='answer'),
        type='opencompass.datasets.musiqueDataset'),
    ]
nq_datasets=[
    dict(abbr='nq',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.nqEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer'),
        type='opencompass.datasets.nqDataset'),
    ]
obqa_datasets=[
    dict(abbr='openbookqa',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.openicl.icl_evaluator.AccEvaluator'),
            pred_postprocessor=dict(
                options='ABCD',
                type='opencompass.utils.text_postprocessors.first_option_postprocess'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='There is a multiple-choice question. Answer the question by choosing "A", "B", "C" or "D". Do not generate any other content.\nQuestion: {question_stem}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'question_stem',
                'A',
                'B',
                'C',
                'D',
                ],
            output_column='answerKey'),
        type='opencompass.datasets.openbookqaDataset'),
    ]
pubhealth_datasets=[
    dict(abbr='PubHealth',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.pubhealthEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Determine whether the given background supports or refutes the claim, and respond with 'SUPPORT' or 'REFUTE'. Do not generate any other content.\nClaim: {claim}\nAnswer: ",
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'claim',
                ],
            output_column='label'),
        type='opencompass.datasets.pubhealthDataset'),
    ]
pubmedQA_datasets=[
    dict(abbr='HotpotQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.pubmedQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt="Based on the background information, determine if the answer to the question is 'YES', 'NO', or 'MAYBE'. Do not generate any other content.\nQuestion: {question}\nAnswer: ",
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns='question',
            output_column='answer'),
        type='opencompass.datasets.pubmedQADataset'),
    ]
triviaqa_datasets=[
    dict(abbr='TriviaQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.TQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                max_out_len=50,
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answer'),
        type='opencompass.datasets.TQADataset'),
    ]
webq_datasets=[
    dict(abbr='WebQ',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.webQEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns=[
                'question',
                ],
            output_column='answers'),
        type='opencompass.datasets.webQDataset'),
    ]
wikimultihop_datasets=[
    dict(abbr='WikiMultihopQA',
        eval_cfg=dict(
            evaluator=dict(
                type='opencompass.datasets.WikiMultihopQAEvaluator'),
            pred_role='BOT'),
        infer_cfg=dict(
            inferencer=dict(
                type='opencompass.openicl.icl_inferencer.GenInferencer'),
            prompt_template=dict(
                template=dict(
                    round=[
                        dict(prompt='Question: {question}\nAnswer: ',
                            role='HUMAN'),
                        ]),
                type='opencompass.openicl.icl_prompt_template.PromptTemplate'),
            retriever=dict(
                type='opencompass.openicl.icl_retriever.ZeroRetriever')),
        reader_cfg=dict(
            input_columns='question',
            output_column='answer'),
        type='opencompass.datasets.WikiMultihopQADataset'),
    ]
work_dir='outputs/default/20240609_164718'