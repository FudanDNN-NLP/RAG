dataset,version,metric,mode,llama-3-8b-ragga-disturb
mmlu_college_biology,77df39,accuracy,gen,92.86
mmlu_college_chemistry,d63112,accuracy,gen,60.00
mmlu_college_computer_science,ecf43e,accuracy,gen,60.00
mmlu_college_mathematics,93a260,accuracy,gen,10.00
mmlu_college_physics,1f8c2b,accuracy,gen,40.00
mmlu_electrical_engineering,47fd74,accuracy,gen,57.14
mmlu_astronomy,a802d4,accuracy,gen,86.67
mmlu_anatomy,48c7b1,accuracy,gen,76.92
mmlu_abstract_algebra,c5eed6,accuracy,gen,40.00
mmlu_machine_learning,fcea76,accuracy,gen,45.45
mmlu_clinical_knowledge,f9efc7,accuracy,gen,70.00
mmlu_global_facts,39218e,accuracy,gen,40.00
mmlu_management,310776,accuracy,gen,80.00
mmlu_nutrition,953bcf,accuracy,gen,70.00
mmlu_marketing,943a6e,accuracy,gen,75.00
mmlu_professional_accounting,193d8a,accuracy,gen,40.00
mmlu_high_school_geography,30f172,accuracy,gen,78.95
mmlu_international_law,2aeb52,accuracy,gen,91.67
mmlu_moral_scenarios,a1413f,accuracy,gen,20.00
mmlu_computer_security,b9eba5,accuracy,gen,70.00
mmlu_high_school_microeconomics,a362fd,accuracy,gen,75.00
mmlu_professional_law,c72987,accuracy,gen,55.00
mmlu_medical_genetics,0628bf,accuracy,gen,90.00
mmlu_professional_psychology,c7a09c,accuracy,gen,75.00
mmlu_jurisprudence,0d56be,accuracy,gen,60.00
mmlu_world_religions,6bb2b9,accuracy,gen,88.24
mmlu_philosophy,b372b5,accuracy,gen,85.00
mmlu_virology,127ecb,accuracy,gen,50.00
mmlu_high_school_chemistry,1d33f3,accuracy,gen,40.00
mmlu_public_relations,ef9df7,accuracy,gen,54.55
mmlu_high_school_macroeconomics,6efa7a,accuracy,gen,80.00
mmlu_human_sexuality,6ec616,accuracy,gen,84.62
mmlu_elementary_mathematics,5be58b,accuracy,gen,45.00
mmlu_high_school_physics,895300,accuracy,gen,33.33
mmlu_high_school_computer_science,66708b,accuracy,gen,50.00
mmlu_high_school_european_history,756fbf,accuracy,gen,68.75
mmlu_business_ethics,96eedd,accuracy,gen,60.00
mmlu_moral_disputes,dc9858,accuracy,gen,55.00
mmlu_high_school_statistics,2f2320,accuracy,gen,55.00
mmlu_miscellaneous,42286f,accuracy,gen,80.00
mmlu_formal_logic,61e6e5,accuracy,gen,66.67
mmlu_high_school_government_and_politics,45ac5f,accuracy,gen,89.47
mmlu_prehistory,e83871,accuracy,gen,75.00
mmlu_security_studies,4405c0,accuracy,gen,65.00
mmlu_high_school_biology,3050f1,accuracy,gen,70.00
mmlu_logical_fallacies,e4ae3b,accuracy,gen,75.00
mmlu_high_school_world_history,d15b35,accuracy,gen,95.00
mmlu_professional_medicine,998a16,accuracy,gen,65.00
mmlu_high_school_mathematics,d09724,accuracy,gen,10.00
mmlu_college_medicine,9ca438,accuracy,gen,58.82
mmlu_high_school_us_history,347c09,accuracy,gen,70.00
mmlu_sociology,0de6fa,accuracy,gen,70.00
mmlu_econometrics,0cb287,accuracy,gen,27.27
mmlu_high_school_psychology,9697d9,accuracy,gen,85.00
mmlu_human_aging,79d875,accuracy,gen,60.00
mmlu_us_foreign_policy,f90662,accuracy,gen,90.00
mmlu_conceptual_physics,51f9f8,accuracy,gen,65.00
