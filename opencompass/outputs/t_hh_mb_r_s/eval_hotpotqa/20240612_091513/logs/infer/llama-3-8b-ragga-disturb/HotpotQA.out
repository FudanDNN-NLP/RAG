06/12 09:15:15 - OpenCompass - INFO - Task****** [llama-3-8b-ragga-disturb/HotpotQA]
06/12 09:15:15 - OpenCompass - WARNING - %%%%%%%%%%%%%%%%%%%%%%%%%%%%jtjjtjtjtjtjtjt:-1
2024-06-12 09:15:16.374208: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-12 09:15:16.427925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-12 09:15:17.183289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.03it/s]
!!!!!!!!!!!!!!!!!!!!IGI
['/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py', 'tmp/1904489_0_params.py']
Building prefix dict from the default dictionary ...
Loading model from cache /data/zfr/.cache/jieba.cache
Loading model cost 0.712 seconds.
Prefix dict has been built successfully.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:05,  1.20it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:02<00:03,  1.27it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:03<00:03,  1.28it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:03<00:02,  1.27it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:04<00:01,  1.27it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:05<00:00,  1.27it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.46it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.33it/s]
/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
!!!!!!!!!!!!!!!!!!!!jt:{'w_q': 0.3, 'w_d': 0.4, 'w_k': 0.3, 'search_k': 10, 'compression_ratio': 0.4, 'top_k': 5, 'Vector_Store': 'milvus', 'with_retrieval_classification': True, 'search_method': 'hyde_with_hybrid', 'rerank_model': 'MonoBERT', 'compression_method': 'recomp', 'repack_method': 'sides'},milvus:1
*****************
init_models
*****************
{'w_q': 0.3, 'w_d': 0.4, 'w_k': 0.3, 'search_k': 10, 'compression_ratio': 0.4, 'top_k': 5, 'Vector_Store': 'milvus', 'with_retrieval_classification': True, 'search_method': 'hyde_with_hybrid', 'rerank_model': 'MonoBERT', 'compression_method': 'recomp', 'repack_method': 'sides'}
milvus:1
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    self._validate_conn(conn)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1096, in _validate_conn
    conn.connect()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connection.py", line 782, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/ssl_.py", line 470, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/ssl_.py", line 514, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/ssl.py", line 513, in wrap_socket
    return self.sslsocket_class._create(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/ssl.py", line 1071, in _create
    self.do_handshake()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/ssl.py", line 1342, in do_handshake
    self._sslobj.do_handshake()
TimeoutError: _ssl.c:990: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 491, in _make_request
    raise new_e
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 469, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 370, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='hf-mirror.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py", line 172, in <module>
    inferencer.run()
  File "/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py", line 88, in run
    self.dataset = build_dataset_from_cfg(self.dataset_cfg)
  File "/data/zfr/finalTest/opencompass/opencompass/utils/build.py", line 13, in build_dataset_from_cfg
    return LOAD_DATASET.build(dataset_cfg)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 98, in build_from_cfg
    obj_cls = registry.get(obj_type)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 451, in get
    self.import_from_location()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 376, in import_from_location
    import_module(loc)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/data/zfr/finalTest/opencompass/opencompass/datasets/__init__.py", line 1, in <module>
    from .advglue import *  # noqa: F401, F403
  File "/data/zfr/finalTest/opencompass/opencompass/datasets/advglue.py", line 6, in <module>
    from opencompass.openicl.icl_evaluator import AccEvaluator
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/__init__.py", line 2, in <module>
    from .icl_evaluator import *  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_evaluator/__init__.py", line 13, in <module>
    from .lm_evaluator import LMEvaluator  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_evaluator/lm_evaluator.py", line 10, in <module>
    from opencompass.openicl.icl_inferencer import GenInferencer
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_inferencer/__init__.py", line 6, in <module>
    from .icl_gen_inferencer import GenInferencer  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_inferencer/icl_gen_inferencer.py", line 54, in <module>
    test_retrieval = jt.JointRetrieval(device="cuda", retrieval_config=retrieval_config, milvus_id=milvus_id)
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 103, in __init__
    ) = self.init_models()
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 165, in init_models
    compressor_model, compressor_tokenizer = init_Compressor_model()
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 118, in init_Compressor_model
    model = AutoModel.from_pretrained("fangyuan/nq_extractive_compressor").to(self.device)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3415, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/api.py", line 100, in head
    return request("head", url, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/adapters.py", line 532, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='hf-mirror.com', port=443): Read timed out. (read timeout=10)
[2024-06-12 09:16:54,660] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1904622) of binary: /data/zfr/anaconda3/envs/joint/bin/python
Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.2.0', 'console_scripts', 'torchrun')())
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-12_09:16:54
  host      : test
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1904622)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
