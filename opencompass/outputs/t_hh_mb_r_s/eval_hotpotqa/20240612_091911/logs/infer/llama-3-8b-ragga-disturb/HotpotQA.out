06/12 09:19:14 - OpenCompass - INFO - Task****** [llama-3-8b-ragga-disturb/HotpotQA]
06/12 09:19:14 - OpenCompass - WARNING - %%%%%%%%%%%%%%%%%%%%%%%%%%%%jtjjtjtjtjtjtjt:-1
2024-06-12 09:19:14.885239: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-12 09:19:14.940979: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-12 09:19:15.696476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.04it/s]
!!!!!!!!!!!!!!!!!!!!IGI
['/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py', 'tmp/1905689_0_params.py']
Building prefix dict from the default dictionary ...
Loading model from cache /data/zfr/.cache/jieba.cache
Loading model cost 0.715 seconds.
Prefix dict has been built successfully.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:00<00:05,  1.19it/s]Loading checkpoint shards:  25%|██▌       | 2/8 [00:01<00:04,  1.24it/s]Loading checkpoint shards:  38%|███▊      | 3/8 [00:02<00:03,  1.27it/s]Loading checkpoint shards:  50%|█████     | 4/8 [00:03<00:03,  1.28it/s]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:03<00:02,  1.27it/s]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:04<00:01,  1.27it/s]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:05<00:00,  1.27it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.46it/s]Loading checkpoint shards: 100%|██████████| 8/8 [00:05<00:00,  1.33it/s]
/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
!!!!!!!!!!!!!!!!!!!!jt:{'w_q': 0.3, 'w_d': 0.4, 'w_k': 0.3, 'search_k': 10, 'compression_ratio': 0.4, 'top_k': 5, 'Vector_Store': 'milvus', 'with_retrieval_classification': True, 'search_method': 'hyde_with_hybrid', 'rerank_model': 'MonoBERT', 'compression_method': 'recomp', 'repack_method': 'sides'},milvus:1
*****************
init_models
*****************
{'w_q': 0.3, 'w_d': 0.4, 'w_k': 0.3, 'search_k': 10, 'compression_ratio': 0.4, 'top_k': 5, 'Vector_Store': 'milvus', 'with_retrieval_classification': True, 'search_method': 'hyde_with_hybrid', 'rerank_model': 'MonoBERT', 'compression_method': 'recomp', 'repack_method': 'sides'}
milvus:1
Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
OSError: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 491, in _make_request
    raise new_e
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    self._validate_conn(conn)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 1096, in _validate_conn
    conn.connect()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connection.py", line 218, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f181913a140>: Failed to establish a new connection: [Errno 101] Network is unreachable

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /castorini/monobert-large-msmarco/resolve/main/model.safetensors (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f181913a140>: Failed to establish a new connection: [Errno 101] Network is unreachable'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py", line 172, in <module>
    inferencer.run()
  File "/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py", line 88, in run
    self.dataset = build_dataset_from_cfg(self.dataset_cfg)
  File "/data/zfr/finalTest/opencompass/opencompass/utils/build.py", line 13, in build_dataset_from_cfg
    return LOAD_DATASET.build(dataset_cfg)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 98, in build_from_cfg
    obj_cls = registry.get(obj_type)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 451, in get
    self.import_from_location()
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/mmengine/registry/registry.py", line 376, in import_from_location
    import_module(loc)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/data/zfr/finalTest/opencompass/opencompass/datasets/__init__.py", line 1, in <module>
    from .advglue import *  # noqa: F401, F403
  File "/data/zfr/finalTest/opencompass/opencompass/datasets/advglue.py", line 6, in <module>
    from opencompass.openicl.icl_evaluator import AccEvaluator
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/__init__.py", line 2, in <module>
    from .icl_evaluator import *  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_evaluator/__init__.py", line 13, in <module>
    from .lm_evaluator import LMEvaluator  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_evaluator/lm_evaluator.py", line 10, in <module>
    from opencompass.openicl.icl_inferencer import GenInferencer
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_inferencer/__init__.py", line 6, in <module>
    from .icl_gen_inferencer import GenInferencer  # noqa
  File "/data/zfr/finalTest/opencompass/opencompass/openicl/icl_inferencer/icl_gen_inferencer.py", line 54, in <module>
    test_retrieval = jt.JointRetrieval(device="cuda", retrieval_config=retrieval_config, milvus_id=milvus_id)
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 103, in __init__
    ) = self.init_models()
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 163, in init_models
    rerank_model, expansion_model, rerank_tokenizer, bert_tokenizer = init_rerank_model()
  File "/data/zfr/finalTest/opencompass/JointTest/JointRetrival2.py", line 145, in init_rerank_model
    rerank_model = MonoBERT()
  File "/data/zfr/finalTest/opencompass/JointTest/reranking/reranking/dlm/pygaggle/pygaggle/rerank/transformer.py", line 359, in __init__
    self.model = model or self.get_model()
  File "/data/zfr/finalTest/opencompass/JointTest/reranking/reranking/dlm/pygaggle/pygaggle/rerank/transformer.py", line 369, in get_model
    return AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path,
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3415, in from_pretrained
    if not has_file(pretrained_model_name_or_path, safe_weights_name, **has_file_kwargs):
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/transformers/utils/hub.py", line 629, in has_file
    r = requests.head(url, headers=headers, allow_redirects=False, proxies=proxies, timeout=10)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/api.py", line 100, in head
    return request("head", url, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/requests/adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /castorini/monobert-large-msmarco/resolve/main/model.safetensors (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f181913a140>: Failed to establish a new connection: [Errno 101] Network is unreachable'))
[2024-06-12 09:20:58,191] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1905791) of binary: /data/zfr/anaconda3/envs/joint/bin/python
Traceback (most recent call last):
  File "/data/zfr/anaconda3/envs/joint/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.2.0', 'console_scripts', 'torchrun')())
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/zfr/anaconda3/envs/joint/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/data/zfr/finalTest/opencompass/opencompass/tasks/openicl_infer.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-12_09:20:58
  host      : test
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1905791)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
